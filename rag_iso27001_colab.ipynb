{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55999cc",
   "metadata": {},
   "source": [
    "**1.- Instalación dependencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc96eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain openai chromadb tiktoken numpy langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e07e9b",
   "metadata": {},
   "source": [
    "**2.- Importar librerías y setup básico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4769c55",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/victor.epitacio/AppData/Local/Microsoft/WindowsApps/python3.13.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Variables globales\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "# API Key - el usuario debe configurar en secrets GitHub o en entorno de Colab\n",
    "#OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "API_KEY=\"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\"\n",
    "OPENAI_API_KEY = API_KEY\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Debe establecerse la variable OPENAI_API_KEY antes de ejecutar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4250b5",
   "metadata": {},
   "source": [
    "**3.- Carga de textos y chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts_and_chunk(path_txt_folder):\n",
    "    text_files = glob.glob(os.path.join(path_txt_folder, '*.txt'))\n",
    "    documents = {}\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator = \"\\n\",\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len\n",
    "    )\n",
    "    for file in text_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        documents[file] = chunks\n",
    "    return documents\n",
    "\n",
    "text_folder = \"./texts/\"\n",
    "documents_chunks = load_texts_and_chunk(text_folder)\n",
    "\n",
    "print(f\"Se cargaron y fragmentaron los textos de la carpeta {text_folder}\")\n",
    "for k,v in documents_chunks.items():\n",
    "    print(f\"Archivo: {os.path.basename(k)} - chunks: {len(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1788d2",
   "metadata": {},
   "source": [
    "**4.- Vectorizar chunks e indexar en ChromaDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chroma_vectorstore(docs_chunks, embedding_model, persist_directory=\"./chroma_db\"):\n",
    "    vectorstores = {}\n",
    "    for filename, chunks in docs_chunks.items():\n",
    "        # Creamos documentos para Langchain (texto por chunk)\n",
    "        from langchain.schema import Document\n",
    "        docs = [Document(page_content=c) for c in chunks]\n",
    "        # Creamos vectorstore Chroma por archivo, persistiendo por separado\n",
    "        db = Chroma.from_documents(docs, embedding_model, persist_directory=f\"{persist_directory}/{os.path.basename(filename)}\")\n",
    "        db.persist()\n",
    "        vectorstores[filename] = db\n",
    "    return vectorstores\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vectorstores = build_chroma_vectorstore(documents_chunks, embedding_model)\n",
    "\n",
    "for k,v in vectorstores.items():\n",
    "    collection = v._collection\n",
    "    print(f\"Vectorstore para {os.path.basename(k)}, vectores total: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8efd01",
   "metadata": {},
   "source": [
    "**5.- Construcción motor RAG con LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Funcion para crear motor RAG para un vectorstore especifico\n",
    "def create_retrieval_qa(vectorstore, temperature=0.3):\n",
    "    llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=temperature)\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc54a8d",
   "metadata": {},
   "source": [
    "**6.- Preguntas de prueba definidas (5 sets, cada set 5-8 preguntas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_sets = [\n",
    "    [ # Set 1\n",
    "        \"¿Cuáles son los requisitos de contraseñas para usuarios visitantes según la política?\",\n",
    "        \"¿Qué permisos tiene un usuario desarrollador para instalación de programas?\",\n",
    "        \"¿Cómo deben conectarse los visitantes a la red corporativa?\",\n",
    "        \"¿Qué controles de acceso aplica la política para usuarios móviles?\",\n",
    "        \"¿Cuándo deben cambiar su contraseña los usuarios administrativos?\"\n",
    "    ],\n",
    "    [ # Set 2\n",
    "        \"¿Qué restricciones hay para usuarios administrativos en el uso de equipos?\",\n",
    "        \"¿Cómo se protege el acceso a internet para usuarios gerenciales?\",\n",
    "        \"¿Cuáles son las políticas para uso de aplicaciones móviles en dispositivos móviles?\",\n",
    "        \"¿Qué procedimientos siguen los visitantes para conectarse a la red?\",\n",
    "        \"¿Qué sanciones se aplican en caso de incumplimiento en la política de contraseñas?\",\n",
    "        \"¿Cómo se controla la instalación de software en dispositivos corporativos?\"\n",
    "    ],\n",
    "    [ # Set 3\n",
    "        \"¿Qué tipo de segmentación de red se usa para visitantes?\",\n",
    "        \"¿Qué controles existen para programas usados por usuarios eventuales?\",\n",
    "        \"¿Cómo deben registrar su ingreso los usuarios eventuales?\",\n",
    "        \"¿Qué accesos especiales tienen los usuarios desarrolladores?\",\n",
    "        \"¿Cómo se debe proteger la información en dispositivos móviles?\"\n",
    "    ],\n",
    "    [ # Set 4\n",
    "        \"¿Cuál es la política para bloqueo en dispositivos móviles?\",\n",
    "        \"¿Qué autorización necesitan los usuarios gerenciales para instalar software?\",\n",
    "        \"¿Cómo se administran los perfiles temporales para usuarios eventuales?\",\n",
    "        \"¿Qué medidas debe tomar un visitante antes de usar su programa en la red?\",\n",
    "        \"¿Qué debe contener la capacitación sobre contraseñas para todos los usuarios?\"\n",
    "    ],\n",
    "    [ # Set 5\n",
    "        \"¿Qué monitoreo existe para detectar intentos de acceso no autorizado?\",\n",
    "        \"¿Cómo se manejan las actualizaciones de software para usuarios administrativos?\",\n",
    "        \"¿Qué implica la política para la retirada segura de equipos?\",\n",
    "        \"¿Cuáles son las características de una contraseña segura para usuarios móviles?\",\n",
    "        \"¿Qué mecanismos debe usar un usuario administrativo para autenticarse?\",\n",
    "        \"¿Cómo se definen los tiempos de acceso para usuarios eventuales?\"\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1aca6",
   "metadata": {},
   "source": [
    "**7.- Evaluación de respuestas y cálculo similitud**\n",
    "\n",
    "Se generarán respuestas para cada pregunta usando temperaturas varias y se calculará la distancia entre embeddings de respuestas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37497c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def embedding_for_text(text, embedding_model):\n",
    "    return np.array(embedding_model.embed_query(text))\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (norm(vec1)*norm(vec2))\n",
    "\n",
    "def cosine_distance(vec1, vec2):\n",
    "    # distancia = 1 - similitud\n",
    "    return 1 - cosine_similarity(vec1, vec2)\n",
    "\n",
    "# Configuraciones de temperatura a evaluar\n",
    "temperatures = [0.2, 0.3, 0.4, 0.7]\n",
    "num_sets = len(question_sets)\n",
    "\n",
    "def evaluate_sets(vectorstores, question_sets, temperatures):\n",
    "    # Recordaremos resultados por set\n",
    "    best_set = -1\n",
    "    best_score = 1000000\n",
    "\n",
    "    for set_idx, questions in enumerate(question_sets):\n",
    "        print(f\"\\nEvaluando Set de Preguntas #{set_idx+1}:\")\n",
    "        total_distances = []\n",
    "        # Para simplicidad, uso una consulta RAG combinada para la indicación\n",
    "        # Selección de vectorstores: Vamos a combinar todas con prioridad la de politica_uso_red.txt por ejemplo\n",
    "        vectorestore_key = list(vectorstores.keys())[2]  # Ejemplo uso 3er vectorstore: politica_uso_red.txt\n",
    "        vectorstore = vectorstores[vectorestore_key]\n",
    "\n",
    "        # Guardar respuestas por pregunta y temperatura\n",
    "        responses = {temp: [] for temp in temperatures}\n",
    "\n",
    "        # Crear motores para cada temperatura\n",
    "        qa_models = {temp: create_retrieval_qa(vectorstore, temperature=temp) for temp in temperatures}\n",
    "\n",
    "        for q in questions:\n",
    "            # generar respuestas para cada temperatura\n",
    "            for temp in temperatures:\n",
    "                response = qa_models[temp].run(q)\n",
    "                responses[temp].append(response)\n",
    "\n",
    "        # Calcular distancia promedio por pregunta / pares temperaturas\n",
    "        # Evaluamos distancias por temperatura (ejemplo todas contra 0.2)\n",
    "        base_temp = 0.2\n",
    "        for i in range(len(questions)):\n",
    "            base_emb = embedding_for_text(responses[base_temp][i], embedding_model)\n",
    "            for temp in temperatures:\n",
    "                if temp == base_temp:\n",
    "                    continue\n",
    "                comp_emb = embedding_for_text(responses[temp][i], embedding_model)\n",
    "                dist = cosine_distance(base_emb, comp_emb)\n",
    "                total_distances.append(dist)\n",
    "                criterio = \"Buena\" if dist <= 0.3 else \"Regular\" if dist <= 0.5 else \"Mala\"\n",
    "                print(f\"\\nPregunta #{i+1}: '{questions[i]}'\")\n",
    "                print(f\"Temperatura {base_temp} vs {temp} - Distancia: {dist:.3f} - Criterio: {criterio}\")\n",
    "\n",
    "        avg_distance = np.mean(total_distances)\n",
    "        print(f\"\\nDistancia promedio para Set #{set_idx+1}: {avg_distance:.3f}\")\n",
    "\n",
    "        if avg_distance < best_score:\n",
    "            best_set = set_idx\n",
    "            best_score = avg_distance\n",
    "\n",
    "    print(\"\\n--------------------------------\")\n",
    "    print(f\"Mejor Set de Preguntas: #{best_set+1} con distancia promedio {best_score:.3f}\")\n",
    "    print(\"--------------------------------\")\n",
    "    return best_set, best_score\n",
    "\n",
    "best_set, best_score = evaluate_sets(vectorstores, question_sets, temperatures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
